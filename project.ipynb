{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fd6fe76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (8.2.50)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from ultralytics) (1.23.5)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from ultralytics) (3.7.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from ultralytics) (9.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from ultralytics) (2.28.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from ultralytics) (1.10.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from ultralytics) (0.17.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from ultralytics) (4.64.1)\n",
      "Requirement already satisfied: psutil in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from ultralytics) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from ultralytics) (2.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (22.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2022.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
      "Requirement already satisfied: filelock in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2022.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/anushkaaprabhat/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch>=1.8.0->ultralytics) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9407aa",
   "metadata": {},
   "source": [
    "# YOLO is a state-of-the-art, real-time object detection algorithm. \n",
    "In this notebook, we will apply the YOLO algorithm to detect objects in images. We have provided a series of images that you can test the YOLO algorithm on. Below is a list of the available images that you can load:\n",
    "birds.png, \n",
    "car.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b1e81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ccac21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvzone\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3ed25a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov10n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dec8740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/anushkaaprabhat/Downloads/YOLOv10-Real-time-Object-Detection-main/birds.png: 384x640 8 birds, 383.7ms\n",
      "Speed: 6.4ms preprocess, 383.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model('birds.png')\n",
    "results[0].show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41fc3af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e9bd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 364.6ms\n",
      "Speed: 4.5ms preprocess, 364.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 337.3ms\n",
      "Speed: 6.8ms preprocess, 337.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.3ms\n",
      "Speed: 2.0ms preprocess, 315.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 331.3ms\n",
      "Speed: 3.1ms preprocess, 331.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 340.4ms\n",
      "Speed: 1.8ms preprocess, 340.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 323.7ms\n",
      "Speed: 2.8ms preprocess, 323.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 316.8ms\n",
      "Speed: 1.7ms preprocess, 316.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 316.7ms\n",
      "Speed: 1.7ms preprocess, 316.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.7ms\n",
      "Speed: 1.9ms preprocess, 315.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.7ms\n",
      "Speed: 1.7ms preprocess, 314.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.9ms\n",
      "Speed: 1.7ms preprocess, 314.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.6ms\n",
      "Speed: 1.7ms preprocess, 313.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.7ms\n",
      "Speed: 1.6ms preprocess, 313.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.3ms\n",
      "Speed: 1.7ms preprocess, 314.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.3ms\n",
      "Speed: 1.7ms preprocess, 313.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.0ms\n",
      "Speed: 1.7ms preprocess, 315.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.6ms\n",
      "Speed: 1.7ms preprocess, 313.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.4ms\n",
      "Speed: 1.6ms preprocess, 313.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.4ms\n",
      "Speed: 1.7ms preprocess, 313.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.0ms\n",
      "Speed: 1.7ms preprocess, 315.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.4ms\n",
      "Speed: 1.7ms preprocess, 313.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.5ms\n",
      "Speed: 1.5ms preprocess, 313.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.2ms\n",
      "Speed: 1.7ms preprocess, 313.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.2ms\n",
      "Speed: 1.6ms preprocess, 312.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.7ms\n",
      "Speed: 1.7ms preprocess, 312.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.4ms\n",
      "Speed: 1.7ms preprocess, 314.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.5ms\n",
      "Speed: 1.6ms preprocess, 313.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.9ms\n",
      "Speed: 1.8ms preprocess, 313.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.9ms\n",
      "Speed: 1.6ms preprocess, 313.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.4ms\n",
      "Speed: 1.6ms preprocess, 313.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.6ms\n",
      "Speed: 1.7ms preprocess, 313.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.4ms\n",
      "Speed: 1.7ms preprocess, 312.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.9ms\n",
      "Speed: 1.7ms preprocess, 313.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.2ms\n",
      "Speed: 1.7ms preprocess, 314.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.8ms\n",
      "Speed: 1.6ms preprocess, 313.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.8ms\n",
      "Speed: 1.7ms preprocess, 313.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.2ms\n",
      "Speed: 1.6ms preprocess, 313.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.1ms\n",
      "Speed: 1.8ms preprocess, 313.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.1ms\n",
      "Speed: 1.7ms preprocess, 313.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.0ms\n",
      "Speed: 1.7ms preprocess, 312.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.1ms\n",
      "Speed: 1.7ms preprocess, 313.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.3ms\n",
      "Speed: 1.7ms preprocess, 312.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.3ms\n",
      "Speed: 1.5ms preprocess, 313.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.7ms\n",
      "Speed: 1.7ms preprocess, 313.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.3ms\n",
      "Speed: 1.7ms preprocess, 314.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.8ms\n",
      "Speed: 1.7ms preprocess, 314.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.4ms\n",
      "Speed: 1.7ms preprocess, 313.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 326.3ms\n",
      "Speed: 1.7ms preprocess, 326.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 340.2ms\n",
      "Speed: 1.6ms preprocess, 340.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 354.6ms\n",
      "Speed: 2.0ms preprocess, 354.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 329.4ms\n",
      "Speed: 1.7ms preprocess, 329.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.6ms\n",
      "Speed: 2.2ms preprocess, 317.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.4ms\n",
      "Speed: 2.5ms preprocess, 318.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 326.7ms\n",
      "Speed: 5.6ms preprocess, 326.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.0ms\n",
      "Speed: 1.7ms preprocess, 313.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.7ms\n",
      "Speed: 1.7ms preprocess, 313.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.4ms\n",
      "Speed: 1.7ms preprocess, 313.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.6ms\n",
      "Speed: 1.7ms preprocess, 313.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.8ms\n",
      "Speed: 1.7ms preprocess, 313.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.4ms\n",
      "Speed: 1.7ms preprocess, 315.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.8ms\n",
      "Speed: 1.7ms preprocess, 313.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret,image = cap.read()\n",
    "    results = model(image)\n",
    "    for info in results:\n",
    "        parameters = info.boxes\n",
    "        for box in parameters:\n",
    "            x1,y1,x2,y2 = box.xyxy[0].numpy().astype('int')\n",
    "            confidence = box.conf[0].numpy().astype('int')*100\n",
    "            class_detected_number = box.cls[0]\n",
    "            class_detected_number = int(class_detected_number)\n",
    "            class_detected_name = results[0].names[class_detected_number]\n",
    "\n",
    "            cv2.rectangle(image,(x1,y1),(x2,y2),(0,0,255),3)\n",
    "            cvzone.putTextRect(image,f'{class_detected_name}',[x1 + 8, y1 - 12], thickness=2,scale=1.5)\n",
    "            \n",
    "    cv2.imshow('frame',image)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929d808e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
